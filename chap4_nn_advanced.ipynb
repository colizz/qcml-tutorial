{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四节：神经网络进阶\n",
    "\n",
    "简单的神经网络，称为前馈神经网络 (feed-forward network)，是处理一维数据时的基础神经网络。\n",
    "\n",
    "对于深度学习两个重要领域：计算机视觉（如图像识别）和自然语言处理（如文本预测），处理的图像、文本的数据形式显然不止一维。这时，如何寻找一个合适的数据的表示（教网络更好地理解这类数据）是很关键的。\n",
    " - 对图像而言，每个像素有RGB值，但是像素按照水平、竖直排列，又增加两个维度。临近的像素和距离较远的像素，地位显然不一样。可否教会网络适应图像类型数据的特点？\n",
    " - 对文本而言，每个单词（文本token）有自己的特征，但是文本是由多个单词构成的，又增加了一个维度。\n",
    "\n",
    "很显然，如果还利用原始的前馈神经网络，把所有输入的特征都“抻”成一维向量，是很笨的做法。\n",
    "\n",
    "卷积神经网络 (CNN) 和循环神经网络 (RNN) 是为适应这些数据形式专门设计的网络。这里先不做详细的介绍。\n",
    "\n",
    "<img src=\"figures/NN_advanced_examples.jpg\" alt=\"image\" width=500/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "Transformer 自2017年诞生，已经“横扫”各个领域，在视觉和文本任务中性能纷纷超过了之前的 CNN 和 RNN 网络架构，称为“大一统”的新型网络架构。除了机器学习领域的任务，Transformer架构也被大量用在科学领域。\n",
    "\n",
    "它是为了处理二维或更高维数据而生的。二维数据：有很多token，每个token是一个特征向量作为输入。\n",
    " - 例如对图像：token可以是16x16的像素块，token特征是对这个小图像块的潜空间的特征\n",
    " - 例如对文本：token可以是基础文本token，特征就是词嵌入特征。\n",
    "\n",
    "Transformer能够高效地学习到这些token之间的联系。\n",
    "\n",
    "Transformer是怎么实现每个token和其它token的“交流”的？\n",
    " - 考虑教室里每个同学是一个token。首先，经过一个线性变换层，将当前同学的特征向量（1维的）转换为三个不同的特征向量（query, key, value)\n",
    " - 每个同学开始和其它所有同学交流。交流方式是，用自己的 query 向量点乘其它同学的 key 向量。这样，每个同学都和其它同学以一个点积的结果连结起来\n",
    " - 对每个同学而言，他和所有N个同学（包括自己）有了N个点积。把这些点积过 softmax (先作e指数后归一），就得到了N个weight。这就是N个同学对自己的“重要性”\n",
    " - 用这些weight来加权每个同学的 value 向量，就是自己更新后的向量了\n",
    " \n",
    "以上操作就是一个 self-attention 操作，下面是一个示意图。\n",
    "\n",
    "<img src=\"figures/attention_illustration.jpg\" alt=\"image\" width=600/>\n",
    "\n",
    "\n",
    "把自己的过一个两层的前馈神经网络 FFN（这是个简单的非线性函数）嵌入到一个新的空间中。\n",
    "\n",
    "把上面的 attention 和 FFN 结合起来，一个 Transformer block 就诞生了。堆叠这个 Transformer block，就构成了简单的 Transformer 网络。[这个博客](https://jalammar.github.io/illustrated-transformer/)对 Transformer 做了不错的可视化介绍，可以参考。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高能物理中的高级网络\n",
    "\n",
    "在高能物理中，喷注鉴别 (jet tagging) 是一个复杂的任务。一个喷注可能包含 ~30 （细喷注）或 ~100 (粗喷注）个粒子，而每个粒子有自己的输入特征，因此，这是一个典型的具有二维数据特征的数据集。\n",
    "\n",
    "CMS和ATLAS组均尝试过诸多前沿的神经网络架构。在CMS中，一个著名的喷注鉴别网络是 DeepAK8，被很多分析使用。它是一个典型的一维CNN网络。\n",
    "后续比较成熟的网络是 ParticleNet，它是一种特殊的图神经网络，但是也具备卷积的特征。\n",
    "\n",
    "我们在下图展示了这些网络的处理流程。它们节选自 **CMS ML 文档**。对于在 CMS 中需要上手使用高级神经网络的同学，可参考这个文档进行练习。\n",
    "\n",
    "https://cms-ml.github.io/documentation/inference/particlenet.html\n",
    "\n",
    "<img src=\"figures/NN_CMS.png\" alt=\"image\" width=1000/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后记\n",
    "\n",
    "最后，我们分享一些深入学习的资料\n",
    "\n",
    "计算机视觉课程：\n",
    " - [UMich EECS 498](https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2020/): Deep Learning for Computer Vision [🔗bilibili](https://www.bilibili.com/video/BV1Yp4y1q7ms)\n",
    "\n",
    "经典文章导读系列：\n",
    " - Bilibili: [跟李沐学AI](https://space.bilibili.com/1567748478/video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
